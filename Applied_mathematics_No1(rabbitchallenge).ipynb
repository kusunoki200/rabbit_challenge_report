{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二章 確率・統計"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 　頻度確率とベイズ確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 頻度確率　\\\n",
    "客観確率とも。事象が発生する頻度を確率と考えるもの。\n",
    "例）6面のサイコロを振って、1が出る確率は1/6である。\n",
    "この確率は無限回の試行で得られる確率。\n",
    "\n",
    "- ベイズ確率 \\\n",
    "主観確率とも。今あるデータから母集団を考える。データが追加で得られたら情報を更新していく。\n",
    "例）診察など"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【条件付確率】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ある事象$X=x$が起こる確率を$P(X=x)$と表す。\n",
    "二つの事象$X, Y$を考えるとき、$X, Y$が同時に起こる確率を同時確率といい、\n",
    "$$\n",
    " P(X=x, Y=y)\n",
    "$$\n",
    "\n",
    "と表す。また、\n",
    "$X=x$が起こった上で、$Y=y$が起こる確率を条件付確率といい、\n",
    "\n",
    "$$\n",
    " P(Y=y|X=x) = \\frac{P(X=x, Y=y)}{P(X=x)}\n",
    "$$\n",
    "と表す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【独立な事象の同時確率】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事象$X, Y$が互いに独立であるとき、同時確率はそれぞれの確立の積であらわされる。\n",
    "$$\n",
    " P(X=x, Y=y) = P(X=x)P(Y=y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【ベイズ則（ベイズの定理】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事象$X, Y$について、\n",
    "\n",
    "$$\n",
    " P(X=x|Y=y)P(Y=y) = P(Y=y|X=x)P(X=x)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    " P(X=x|Y=y) = \\frac{P(Y=y|X=x)P(X=x)}{P(Y=y)} = \\frac{P(Y=y|X=x)P(X=x)}{\\sum{P(Y|X)P(X)}}\n",
    "$$\n",
    "\n",
    "が成り立つ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 例\n",
    "つぼAに赤玉が1個、白玉が5個。つぼBに赤玉が5個、白玉が１個入っているとする。\n",
    "今、どちらのつぼから取り出したかはわからないが、取り出した玉が赤色だった。このとき、各ツボから取り出した確率を求める。つぼの選択する事象を$X={A,B}$、玉の色を事象$Y={赤, 白}$とするとき,$P(X|Y)$を求めればよい。\n",
    "前提として、\n",
    "$$\n",
    "P(X=A)=P(X=B) = \\frac{1}{2}\n",
    "$$\n",
    "とすると、\n",
    "$$\n",
    "P(X=A|Y=赤) = \\frac{P(Y=赤|X=A)P(X=A)}{P(Y=赤|X=A)P(X=A) + P(Y=赤|X=B)P(X=B)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結局,\n",
    "$$\n",
    " P(X=A|Y=赤) = \\frac{1/6 \\times 1/2}{1/6\\times 1/2 + 5/6 \\times 1/2} = \\frac{1}{6}\n",
    "$$\n",
    "と求まる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【確率変数と確率分布】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 確率変数 \\\n",
    "事象と結びつけられた数値（サイコロの目など）であり、その値に対して確率が与えられている変数のこと。\n",
    "\n",
    "- 確率分布 \\\n",
    "事象が発生する確率の分布。\n",
    "離散型の確率変数であれば、表に表すことが可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【離散確率分布と連続確率分布】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率変数$X$が離散的な値$\\{x_1, x_2, \\dots \\}$をとるとき、$X$を離散確率変数といい、それぞれの確率の値\n",
    "$$\n",
    " P(X=x_k) = f(x_k)\n",
    "$$\n",
    "\n",
    "を$X$の確率分布という。$f$は$f(x_k) \\geq 0$かつ$\\sum_i^{\\infty} f(x_i) = 1$を満たす。\n",
    "\n",
    "\n",
    "\n",
    "また、$X$が連続した値を持つとき、$X$がある範囲$(a～b)$をとる確率が、\n",
    "$$\n",
    " P(a \\leq X \\leq b) = \\int_{a}^{b} f(x) dx\n",
    "$$\n",
    "と表され、\n",
    "$$\n",
    " f(x) \\geq 0 {かつ} \\ \\int_{-\\infty}^{\\infty} f(x) dx = 1\n",
    "$$\n",
    "を満たす、f(x)を$X$の確率密度関数という。連続確率分布の場合、ある一点（X=a）の確率$P(X=a)$は0となる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【期待値/分散/共分散】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 期待値：得られるであろう予測される値（重み付きの平均）\n",
    "$$\n",
    " E(X) = \\sum_{k=1}^{n} P(X=x_k)f(X=x_k) \\ {または}\\ E(X) = \\int_{-\\infty}^{\\infty} x f(x) dx \n",
    "$$\n",
    "\n",
    "- 分散:データの散らばり具合、各データが期待値からどれだけ離れているかを平均したもの。\n",
    "分散の平方根が標準偏差\n",
    "$$\n",
    " Var(X) = E((f(X=x) - E(X))^2) = E(f(x^2)) - E(X)^2\n",
    "$$\n",
    "\n",
    "-　共分散：二つのデータの傾向の指標、値が正なら似た傾向、負なら逆、０なら関係は乏しい。\n",
    "$$\n",
    " Cov(X,Y) = E[(f(X)-E(X))(f(Y)-E(Y))]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【確率分布の例】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ベルヌーイ分布\n",
    "コイントスの裏表のように、2種類の可能な結果があり、その確率が$p$, $1-p$で1回試行するときの分布。\\\n",
    "$n$回試行の場合は2項分布になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    " f(\\chi;p) = p^\\chi(1-p)^{1-\\chi}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二項分布\n",
    "ベルヌーイ試行をn回繰り返すときの分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    " f(\\chi;p,n) = {}_n C _\\chi p^\\chi (1-p)^{1-\\chi}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ガウス分布\n",
    "連続型の分布。多くの減少に当てはまる分布。\n",
    "$$\n",
    " f(x;\\mu, \\sigma^2) = \\sqrt{\\frac{1}{2 \\pi \\sigma^2}} \\exp \\left(-\\frac{1}{2}(x - \\mu)^2 \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第3章　情報理論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【自己情報量】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定義\n",
    "$$\n",
    " I(x) = - \\log(P(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対数の底によって単位が変わる。2のときビット[bit],10のときディット[dit],eのときナット[nat]。 \\\n",
    "確率の低い事象のほうが起きたとき情報量が大きくなる。確率は1以下なので、情報量は正の値をとる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【シャノンエントロピー】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自己情報量の期待値\n",
    "$$\n",
    " H(x) = E(I(x)) = -E(\\log(P(x)) = - \\Sigma(P(x)\\log(P(x)))\n",
    "$$\n",
    "\n",
    "エントロピーは乱雑さを表す。確率の話では、確率変数がどの値をとるか当てにくいような状態。つまり、確率変数がそれぞれの値をとる確率がどれだけ違うかを表す値。一様分布のような場合はエントロピーは大きくなる。反対にある特定の値をとりやすく、他の値は取りにくく偏りがあるような確率分布の場合はエントロピーは小さくなる。エントロピーは確率分布に対して定義される。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【カルバック・ライブラー ダイバージェンス】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定義\n",
    "$$\n",
    " D_{KL} (P||Q) = E_{x \\sim P}\\left[\\log \\frac{P(x)}{Q(x)} \\right]  = E_{x \\sim P} \\left[\\log P(x)-\\log Q(x) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二つの確率分布がどれだけ異なるかを測る指標。エントロピーと同様確率分布に対して定義される。\n",
    "上記の定義はPから見たQのKLダイバージェンス。同じ事象の確率分布同士でないと定義できない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【交差エントロピー】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定義\n",
    "$$\n",
    " H(P, Q)  = -P(x) \\log Q(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(x)$が真の分布,$Q(x)$が予測の分布。予測した分布が真の分布に近いほど交差エントロピーは小さくなる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    " H(P,Q) = H(P) +  D_{KL} (P||Q)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
